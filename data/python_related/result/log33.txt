C:\Apps\Python\python.exe C:\Users\gklizh\Documents\Workspace\code_and_data\code\autoencoder.py 
(463, 4983)
(463, 4983)
iteration 0
first source ...
second source ...
features size of the 1st dataset: 301
features size of the 2nd dataset: 301
shape of n_hidden1  301
shape of n_hidden2  301
2024-01-13 18:10:05.936966: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
---------Start trial----------------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([1.1710412502288818, 1.1722536087036133, 1.1780532598495483, 1.1543692350387573, 1.1687172651290894, 1.1783381700515747, 1.1661748886108398, 1.175642728805542, 1.175020694732666, 1.1879258155822754, 1.1626696586608887, 1.1686686277389526, 1.1740059852600098, 1.1669723987579346, 1.1651885509490967, 1.1616681814193726, 1.1773712635040283, 1.177727222442627, 1.1786303520202637, 1.1790282726287842, 1.1733819246292114, 1.1753828525543213])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973])
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([1.2036032676696777, 1.1967189311981201, 1.1963207721710205, 1.1975153684616089, 1.200966715812683, 1.2000879049301147, 1.2075817584991455, 1.1995822191238403, 1.1924293041229248, 1.1966489553451538, 1.1918021440505981, 1.2027925252914429, 1.20279860496521, 1.1951967477798462, 1.1994341611862183, 1.198257565498352, 1.2091176509857178, 1.1994805335998535, 1.2098127603530884, 1.1964839696884155, 1.2005566358566284, 1.1985372304916382])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802])
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([28.864713668823242, 28.84758758544922, 28.858444213867188, 28.85378074645996, 28.853271484375, 28.86993980407715, 28.857030868530273, 28.873010635375977, 28.862443923950195, 28.860668182373047, 28.851884841918945, 28.878042221069336, 28.878692626953125, 28.854806900024414, 28.854440689086914, 28.86379623413086, 28.870174407958984, 28.859317779541016, 28.877538681030273, 28.871936798095703, 28.86911964416504, 28.868288040161133])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621])
100%|██████████| 3/3 [28:50<00:00, 576.95s/trial, best loss: 0.46634921431541443]
------------------Got the best value----------
{'alpha': 0, 'batch_size': 1, 'initializer': 0, 'lamda': 0, 'learning_rate': 0.28219638609587394, 'optimizer': 4, 'units1': 112, 'units2': 18}
-----------------------End output best------------
------------test train starts--------------------
-------------------end the train test-------------------------
The loss value : tf.Tensor(1.1227461, shape=(), dtype=float32)
-------------display best ----------------------
dict_items([('alpha', 0), ('batch_size', 1), ('initializer', 0), ('lamda', 0), ('learning_rate', 0.28219638609587394), ('optimizer', 4), ('units1', 112), ('units2', 18)])
-------------Time count--------------------
The total time it took is about 1756.247984799964 seconds
-------------Time count--------------------
iteration 1
first source ...
second source ...
features size of the 1st dataset: 191
features size of the 2nd dataset: 191
shape of n_hidden1  191
shape of n_hidden2  191
---------Start trial----------------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([3.6271746158599854, 3.640456438064575, 3.6286001205444336, 3.624752998352051, 3.6431021690368652, 3.6332037448883057, 3.6322662830352783, 3.6357855796813965, 3.634377956390381, 3.633453607559204, 3.6249566078186035, 3.6305410861968994, 3.633918285369873, 3.6290667057037354, 3.637183427810669, 3.639007806777954, 3.6339497566223145, 3.6395585536956787, 3.635068893432617, 3.6240785121917725, 3.6251111030578613, 3.633880376815796])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867])
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([1.2441407442092896, 1.259062647819519, 1.255826473236084, 1.251262903213501, 1.2563945055007935, 1.2572590112686157, 1.2583411931991577, 1.2540851831436157, 1.257503867149353, 1.2532209157943726, 1.2485923767089844, 1.2644693851470947, 1.2580070495605469, 1.2461695671081543, 1.2503174543380737, 1.258800983428955, 1.2530293464660645, 1.2512104511260986, 1.263697624206543, 1.2527996301651, 1.2555208206176758, 1.2656389474868774])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986])
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([1.2374002933502197, 1.230564832687378, 1.2451775074005127, 1.2429289817810059, 1.2314777374267578, 1.2407197952270508, 1.2365610599517822, 1.2323704957962036, 1.241767406463623, 1.2427501678466797, 1.2312415838241577, 1.2252804040908813, 1.2411222457885742, 1.2280508279800415, 1.229871153831482, 1.2312527894973755, 1.2216753959655762, 1.2295782566070557, 1.2375240325927734, 1.2319309711456299, 1.2303084135055542, 1.236307144165039])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397])
100%|██████████| 3/3 [25:10<00:00, 503.39s/trial, best loss: 0.47975438833236694]
------------------Got the best value----------
{'alpha': 1, 'alpha2': 0.15504722718670916, 'batch_size': 0, 'initializer': 0, 'lamda': 0, 'learning_rate': 0.008117050027524596, 'optimizer': 2, 'units1': 188, 'units2': 113}
-----------------------End output best------------
------------test train starts--------------------
-------------------end the train test-------------------------
The loss value : tf.Tensor(1.2132071, shape=(), dtype=float32)
-------------display best ----------------------
dict_items([('alpha', 1), ('alpha2', 0.15504722718670916), ('batch_size', 0), ('initializer', 0), ('lamda', 0), ('learning_rate', 0.008117050027524596), ('optimizer', 2), ('units1', 188), ('units2', 113)])
-------------Time count--------------------
The total time it took is about 3276.1641556000104 seconds
-------------Time count--------------------
-----Trails record history--------
dict_items([('trial_0', <hyperopt.base.Trials object at 0x000001A8DC223610>), ('trial_1', <hyperopt.base.Trials object at 0x000001A97B3832D0>)])
----------------------------------

Data for trial_0:

Data for trial_1:

Data for trial_0:
{'state': 2, 'tid': 0, 'spec': None, 'result': {'loss': 0.46634921431541443, 'status': 'ok', 'params': {'alpha': 0, 'batch_size': 8, 'initializer': 'xavier', 'lamda': 0, 'learning_rate': 0.28219638609587394, 'optimizer': 'RMSProp', 'units1': 113, 'units2': 19}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=0.4684165>, 'history_loss': ListWrapper([1.1710412502288818, 1.1722536087036133, 1.1780532598495483, 1.1543692350387573, 1.1687172651290894, 1.1783381700515747, 1.1661748886108398, 1.175642728805542, 1.175020694732666, 1.1879258155822754, 1.1626696586608887, 1.1686686277389526, 1.1740059852600098, 1.1669723987579346, 1.1651885509490967, 1.1616681814193726, 1.1773712635040283, 1.177727222442627, 1.1786303520202637, 1.1790282726287842, 1.1733819246292114, 1.1753828525543213]), 'history_val_loss': ListWrapper([1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973, 1.1658730506896973])}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [0], 'alpha2': [], 'batch_size': [0], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0], 'optimizer': [0], 'units1': [0], 'units2': [0]}, 'vals': {'alpha': [0], 'alpha2': [], 'batch_size': [1], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0.28219638609587394], 'optimizer': [4], 'units1': [112], 'units2': [18]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 16, 10, 6, 44000), 'refresh_time': datetime.datetime(2024, 1, 13, 16, 16, 30, 29000)}
{'state': 2, 'tid': 1, 'spec': None, 'result': {'loss': 0.47555088996887207, 'status': 'ok', 'params': {'alpha': 0.6216918884773958, 'batch_size': 4, 'initializer': 'xavier', 'lamda': 0, 'learning_rate': 0.21223397050924306, 'optimizer': 'adam', 'units1': 37, 'units2': 48}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=0.48144132>, 'history_loss': ListWrapper([1.2036032676696777, 1.1967189311981201, 1.1963207721710205, 1.1975153684616089, 1.200966715812683, 1.2000879049301147, 1.2075817584991455, 1.1995822191238403, 1.1924293041229248, 1.1966489553451538, 1.1918021440505981, 1.2027925252914429, 1.20279860496521, 1.1951967477798462, 1.1994341611862183, 1.198257565498352, 1.2091176509857178, 1.1994805335998535, 1.2098127603530884, 1.1964839696884155, 1.2005566358566284, 1.1985372304916382]), 'history_val_loss': ListWrapper([1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802, 1.1888772249221802])}, 'misc': {'tid': 1, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [1], 'alpha2': [1], 'batch_size': [1], 'initializer': [1], 'lamda': [1], 'lamda2': [], 'learning_rate': [1], 'optimizer': [1], 'units1': [1], 'units2': [1]}, 'vals': {'alpha': [1], 'alpha2': [0.6216918884773958], 'batch_size': [2], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0.21223397050924306], 'optimizer': [0], 'units1': [36], 'units2': [47]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 16, 16, 30, 40000), 'refresh_time': datetime.datetime(2024, 1, 13, 16, 30, 45, 739000)}
{'state': 2, 'tid': 2, 'spec': None, 'result': {'loss': 11.557161331176758, 'status': 'ok', 'params': {'alpha': 0, 'batch_size': 8, 'initializer': 'xavier', 'lamda': 0.0009000459304264379, 'learning_rate': 0.03199000491114938, 'optimizer': 'RMSProp', 'units1': 155, 'units2': 261}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=11.545885>, 'history_loss': ListWrapper([28.864713668823242, 28.84758758544922, 28.858444213867188, 28.85378074645996, 28.853271484375, 28.86993980407715, 28.857030868530273, 28.873010635375977, 28.862443923950195, 28.860668182373047, 28.851884841918945, 28.878042221069336, 28.878692626953125, 28.854806900024414, 28.854440689086914, 28.86379623413086, 28.870174407958984, 28.859317779541016, 28.877538681030273, 28.871936798095703, 28.86911964416504, 28.868288040161133]), 'history_val_loss': ListWrapper([28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621, 28.89290428161621])}, 'misc': {'tid': 2, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [2], 'alpha2': [], 'batch_size': [2], 'initializer': [2], 'lamda': [2], 'lamda2': [2], 'learning_rate': [2], 'optimizer': [2], 'units1': [2], 'units2': [2]}, 'vals': {'alpha': [0], 'alpha2': [], 'batch_size': [1], 'initializer': [0], 'lamda': [1], 'lamda2': [0.0009000459304264379], 'learning_rate': [0.03199000491114938], 'optimizer': [4], 'units1': [154], 'units2': [260]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 16, 30, 45, 755000), 'refresh_time': datetime.datetime(2024, 1, 13, 16, 38, 56, 812000)}

Data for trial_1:
{'state': 2, 'tid': 0, 'spec': None, 'result': {'loss': 1.4460887908935547, 'status': 'ok', 'params': {'alpha': 0.6813603469500131, 'batch_size': 4, 'initializer': 'xavier', 'lamda': 0.000448233743208072, 'learning_rate': 0.14499623558403105, 'optimizer': 'SGD', 'units1': 173, 'units2': 54}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=1.4508698>, 'history_loss': ListWrapper([3.6271746158599854, 3.640456438064575, 3.6286001205444336, 3.624752998352051, 3.6431021690368652, 3.6332037448883057, 3.6322662830352783, 3.6357855796813965, 3.634377956390381, 3.633453607559204, 3.6249566078186035, 3.6305410861968994, 3.633918285369873, 3.6290667057037354, 3.637183427810669, 3.639007806777954, 3.6339497566223145, 3.6395585536956787, 3.635068893432617, 3.6240785121917725, 3.6251111030578613, 3.633880376815796]), 'history_val_loss': ListWrapper([3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867, 3.6152219772338867])}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [0], 'alpha2': [0], 'batch_size': [0], 'initializer': [0], 'lamda': [0], 'lamda2': [0], 'learning_rate': [0], 'optimizer': [0], 'units1': [0], 'units2': [0]}, 'vals': {'alpha': [1], 'alpha2': [0.6813603469500131], 'batch_size': [2], 'initializer': [0], 'lamda': [1], 'lamda2': [0.000448233743208072], 'learning_rate': [0.14499623558403105], 'optimizer': [2], 'units1': [172], 'units2': [53]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 16, 39, 19, 288000), 'refresh_time': datetime.datetime(2024, 1, 13, 16, 50, 28, 400000)}
{'state': 2, 'tid': 1, 'spec': None, 'result': {'loss': 0.495699018239975, 'status': 'ok', 'params': {'alpha': 0.16738010994745212, 'batch_size': 4, 'initializer': 'xavier', 'lamda': 0, 'learning_rate': 0.01679713997879656, 'optimizer': 'SGD', 'units1': 99, 'units2': 14}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=0.4976563>, 'history_loss': ListWrapper([1.2441407442092896, 1.259062647819519, 1.255826473236084, 1.251262903213501, 1.2563945055007935, 1.2572590112686157, 1.2583411931991577, 1.2540851831436157, 1.257503867149353, 1.2532209157943726, 1.2485923767089844, 1.2644693851470947, 1.2580070495605469, 1.2461695671081543, 1.2503174543380737, 1.258800983428955, 1.2530293464660645, 1.2512104511260986, 1.263697624206543, 1.2527996301651, 1.2555208206176758, 1.2656389474868774]), 'history_val_loss': ListWrapper([1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986, 1.2392475605010986])}, 'misc': {'tid': 1, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [1], 'alpha2': [1], 'batch_size': [1], 'initializer': [1], 'lamda': [1], 'lamda2': [], 'learning_rate': [1], 'optimizer': [1], 'units1': [1], 'units2': [1]}, 'vals': {'alpha': [1], 'alpha2': [0.16738010994745212], 'batch_size': [2], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0.01679713997879656], 'optimizer': [2], 'units1': [98], 'units2': [13]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 16, 50, 28, 410000), 'refresh_time': datetime.datetime(2024, 1, 13, 17, 1, 33, 733000)}
{'state': 2, 'tid': 2, 'spec': None, 'result': {'loss': 0.47975438833236694, 'status': 'ok', 'params': {'alpha': 0.15504722718670916, 'batch_size': 16, 'initializer': 'xavier', 'lamda': 0, 'learning_rate': 0.008117050027524596, 'optimizer': 'SGD', 'units1': 189, 'units2': 114}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=0.49496013>, 'history_loss': ListWrapper([1.2374002933502197, 1.230564832687378, 1.2451775074005127, 1.2429289817810059, 1.2314777374267578, 1.2407197952270508, 1.2365610599517822, 1.2323704957962036, 1.241767406463623, 1.2427501678466797, 1.2312415838241577, 1.2252804040908813, 1.2411222457885742, 1.2280508279800415, 1.229871153831482, 1.2312527894973755, 1.2216753959655762, 1.2295782566070557, 1.2375240325927734, 1.2319309711456299, 1.2303084135055542, 1.236307144165039]), 'history_val_loss': ListWrapper([1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397, 1.1993860006332397])}, 'misc': {'tid': 2, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [2], 'alpha2': [2], 'batch_size': [2], 'initializer': [2], 'lamda': [2], 'lamda2': [], 'learning_rate': [2], 'optimizer': [2], 'units1': [2], 'units2': [2]}, 'vals': {'alpha': [1], 'alpha2': [0.15504722718670916], 'batch_size': [0], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0.008117050027524596], 'optimizer': [2], 'units1': [188], 'units2': [113]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 17, 1, 33, 742000), 'refresh_time': datetime.datetime(2024, 1, 13, 17, 4, 29, 446000)}

Process finished with exit code 0
