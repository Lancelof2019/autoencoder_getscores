C:\Apps\Python\python.exe C:\Users\gklizh\Documents\Workspace\code_and_data\code\autoencoder.py 
(463, 4983)
(463, 4983)
iteration 0
first source ...
second source ...
features size of the 1st dataset: 301
features size of the 2nd dataset: 301
shape of n_hidden1  301
shape of n_hidden2  301
---------Start trial----------------
2024-01-13 17:11:31.459147: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE SSE2 SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([1.2126981019973755, 1.2087730169296265, 1.2175573110580444, 1.2037856578826904, 1.2030420303344727, 1.2155083417892456, 1.2077020406723022, 1.2145239114761353, 1.2124098539352417, 1.2073419094085693, 1.2210265398025513, 1.2096112966537476, 1.205543041229248, 1.20188307762146, 1.2029410600662231, 1.2178165912628174, 1.2161964178085327, 1.213926076889038, 1.216646432876587, 1.212753176689148, 1.2098157405853271, 1.2072988748550415])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006])
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([1.2018787860870361, 1.2063539028167725, 1.205190658569336, 1.2063767910003662, 1.2092877626419067, 1.2162950038909912, 1.2082595825195312, 1.2110097408294678, 1.213979721069336, 1.2159901857376099, 1.2107435464859009, 1.2071202993392944, 1.2082915306091309, 1.2068227529525757, 1.2135564088821411, 1.2108629941940308, 1.219068169593811, 1.2103394269943237, 1.20772123336792, 1.2126582860946655, 1.2022836208343506, 1.2003291845321655])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268])
100%|██████████| 2/2 [26:50<00:00, 805.49s/trial, best loss: 0.4775198996067047]
------------------Got the best value----------
{'alpha': 1, 'alpha2': 0.07296810136097998, 'batch_size': 2, 'initializer': 0, 'lamda': 0, 'learning_rate': 0.10993983752716435, 'optimizer': 3, 'units1': 162, 'units2': 105}
-----------------------End output best------------
------------test train starts--------------------
-------------------end the train test-------------------------
The loss value : tf.Tensor(1.1696976, shape=(), dtype=float32)
-------------display best ----------------------
dict_items([('alpha', 1), ('alpha2', 0.07296810136097998), ('batch_size', 2), ('initializer', 0), ('lamda', 0), ('learning_rate', 0.10993983752716435), ('optimizer', 3), ('units1', 162), ('units2', 105)])
-------------Time count--------------------
The total time it took is about 1666.7699275999912 seconds
-------------Time count--------------------
iteration 1
first source ...
second source ...
features size of the 1st dataset: 191
features size of the 2nd dataset: 191
shape of n_hidden1  191
shape of n_hidden2  191
---------Start trial----------------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([1.2505677938461304, 1.2517249584197998, 1.2479594945907593, 1.2454333305358887, 1.255246639251709, 1.2436599731445312, 1.2494398355484009, 1.2465423345565796, 1.2390961647033691, 1.240504503250122, 1.246726632118225, 1.2442158460617065, 1.238886833190918, 1.2466026544570923, 1.2497622966766357, 1.239141821861267, 1.244986653327942, 1.2551896572113037, 1.2390213012695312, 1.239683747291565, 1.2492995262145996, 1.2347973585128784])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538])
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
train_index
(296,)
val_index
(74,)
---------------TRain starts---------
************************The crossvalidation ->hiscosts:*********************
ListWrapper([7.671971797943115, 7.671217441558838, 7.670654773712158, 7.660071849822998, 7.6681227684021, 7.675894737243652, 7.659188270568848, 7.665706634521484, 7.666324138641357, 7.665531635284424, 7.664738178253174, 7.6650004386901855, 7.672377586364746, 7.668874740600586, 7.673197269439697, 7.665483474731445, 7.678366661071777, 7.663706302642822, 7.6630167961120605, 7.662611484527588, 7.668199062347412, 7.666332721710205])
************************The crossvalidation ->hist_val_costs:*********************
ListWrapper([7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422])
100%|██████████| 2/2 [07:16<00:00, 218.33s/trial, best loss: 0.48012441396713257]
------------------Got the best value----------
{'alpha': 1, 'alpha2': 0.8207928317756371, 'batch_size': 0, 'initializer': 0, 'lamda': 0, 'learning_rate': 0.13203257973416752, 'optimizer': 4, 'units1': 53, 'units2': 151}
-----------------------End output best------------
------------test train starts--------------------
-------------------end the train test-------------------------
The loss value : tf.Tensor(1.1826153, shape=(), dtype=float32)
-------------display best ----------------------
dict_items([('alpha', 1), ('alpha2', 0.8207928317756371), ('batch_size', 0), ('initializer', 0), ('lamda', 0), ('learning_rate', 0.13203257973416752), ('optimizer', 4), ('units1', 53), ('units2', 151)])
-------------Time count--------------------
The total time it took is about 2116.2438919999986 seconds
-------------Time count--------------------
-----Trails record history--------
dict_items([('trial_0', <hyperopt.base.Trials object at 0x0000023D3F2A51D0>), ('trial_1', <hyperopt.base.Trials object at 0x0000023D3F94AD90>)])

Data for trial_0:
{'state': 2, 'tid': 0, 'spec': None, 'result': {'loss': 0.4775198996067047, 'status': 'ok', 'params': {'alpha': 0.07296810136097998, 'batch_size': 4, 'initializer': 'xavier', 'lamda': 0, 'learning_rate': 0.10993983752716435, 'optimizer': 'Momentum', 'units1': 163, 'units2': 106}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=0.48507923>, 'history_loss': ListWrapper([1.2126981019973755, 1.2087730169296265, 1.2175573110580444, 1.2037856578826904, 1.2030420303344727, 1.2155083417892456, 1.2077020406723022, 1.2145239114761353, 1.2124098539352417, 1.2073419094085693, 1.2210265398025513, 1.2096112966537476, 1.205543041229248, 1.20188307762146, 1.2029410600662231, 1.2178165912628174, 1.2161964178085327, 1.213926076889038, 1.216646432876587, 1.212753176689148, 1.2098157405853271, 1.2072988748550415]), 'history_val_loss': ListWrapper([1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006, 1.1937997341156006])}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [0], 'alpha2': [0], 'batch_size': [0], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0], 'optimizer': [0], 'units1': [0], 'units2': [0]}, 'vals': {'alpha': [1], 'alpha2': [0.07296810136097998], 'batch_size': [2], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0.10993983752716435], 'optimizer': [3], 'units1': [162], 'units2': [105]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 15, 11, 31, 580000), 'refresh_time': datetime.datetime(2024, 1, 13, 15, 23, 59, 137000)}
{'state': 2, 'tid': 1, 'spec': None, 'result': {'loss': 0.4944371283054352, 'status': 'ok', 'params': {'alpha': 0, 'batch_size': 4, 'initializer': 'xavier', 'lamda': 0, 'learning_rate': 0.02306312874491768, 'optimizer': 'adam', 'units1': 92, 'units2': 71}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=0.4807515>, 'history_loss': ListWrapper([1.2018787860870361, 1.2063539028167725, 1.205190658569336, 1.2063767910003662, 1.2092877626419067, 1.2162950038909912, 1.2082595825195312, 1.2110097408294678, 1.213979721069336, 1.2159901857376099, 1.2107435464859009, 1.2071202993392944, 1.2082915306091309, 1.2068227529525757, 1.2135564088821411, 1.2108629941940308, 1.219068169593811, 1.2103394269943237, 1.20772123336792, 1.2126582860946655, 1.2022836208343506, 1.2003291845321655]), 'history_val_loss': ListWrapper([1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268, 1.2360928058624268])}, 'misc': {'tid': 1, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [1], 'alpha2': [], 'batch_size': [1], 'initializer': [1], 'lamda': [1], 'lamda2': [], 'learning_rate': [1], 'optimizer': [1], 'units1': [1], 'units2': [1]}, 'vals': {'alpha': [0], 'alpha2': [], 'batch_size': [2], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0.02306312874491768], 'optimizer': [0], 'units1': [91], 'units2': [70]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 15, 23, 59, 150000), 'refresh_time': datetime.datetime(2024, 1, 13, 15, 38, 22, 483000)}

Data for trial_1:
{'state': 2, 'tid': 0, 'spec': None, 'result': {'loss': 0.48012441396713257, 'status': 'ok', 'params': {'alpha': 0.8207928317756371, 'batch_size': 16, 'initializer': 'xavier', 'lamda': 0, 'learning_rate': 0.13203257973416752, 'optimizer': 'RMSProp', 'units1': 54, 'units2': 152}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=0.5002271>, 'history_loss': ListWrapper([1.2505677938461304, 1.2517249584197998, 1.2479594945907593, 1.2454333305358887, 1.255246639251709, 1.2436599731445312, 1.2494398355484009, 1.2465423345565796, 1.2390961647033691, 1.240504503250122, 1.246726632118225, 1.2442158460617065, 1.238886833190918, 1.2466026544570923, 1.2497622966766357, 1.239141821861267, 1.244986653327942, 1.2551896572113037, 1.2390213012695312, 1.239683747291565, 1.2492995262145996, 1.2347973585128784]), 'history_val_loss': ListWrapper([1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538, 1.2003110647201538])}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [0], 'alpha2': [0], 'batch_size': [0], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0], 'optimizer': [0], 'units1': [0], 'units2': [0]}, 'vals': {'alpha': [1], 'alpha2': [0.8207928317756371], 'batch_size': [0], 'initializer': [0], 'lamda': [0], 'lamda2': [], 'learning_rate': [0.13203257973416752], 'optimizer': [4], 'units1': [53], 'units2': [151]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 15, 39, 15, 383000), 'refresh_time': datetime.datetime(2024, 1, 13, 15, 42, 34, 253000)}
{'state': 2, 'tid': 1, 'spec': None, 'result': {'loss': 3.0736985206604004, 'status': 'ok', 'params': {'alpha': 0, 'batch_size': 16, 'initializer': 'xavier', 'lamda': 0.0007412456051561628, 'learning_rate': 0.12495206608411309, 'optimizer': 'nadam', 'units1': 151, 'units2': 41}, 'loss_train': <tf.Tensor: shape=(), dtype=float32, numpy=3.0687888>, 'history_loss': ListWrapper([7.671971797943115, 7.671217441558838, 7.670654773712158, 7.660071849822998, 7.6681227684021, 7.675894737243652, 7.659188270568848, 7.665706634521484, 7.666324138641357, 7.665531635284424, 7.664738178253174, 7.6650004386901855, 7.672377586364746, 7.668874740600586, 7.673197269439697, 7.665483474731445, 7.678366661071777, 7.663706302642822, 7.6630167961120605, 7.662611484527588, 7.668199062347412, 7.666332721710205]), 'history_val_loss': ListWrapper([7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422, 7.684246063232422])}, 'misc': {'tid': 1, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'alpha': [1], 'alpha2': [], 'batch_size': [1], 'initializer': [1], 'lamda': [1], 'lamda2': [1], 'learning_rate': [1], 'optimizer': [1], 'units1': [1], 'units2': [1]}, 'vals': {'alpha': [0], 'alpha2': [], 'batch_size': [0], 'initializer': [0], 'lamda': [1], 'lamda2': [0.0007412456051561628], 'learning_rate': [0.12495206608411309], 'optimizer': [1], 'units1': [150], 'units2': [40]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': datetime.datetime(2024, 1, 13, 15, 42, 34, 264000), 'refresh_time': datetime.datetime(2024, 1, 13, 15, 46, 32, 28000)}

Process finished with exit code 0
